\chapter{Probability}  % 4
    \section{Experiments, Sample Spaces, Events}  % 4.1
        \subsection{Experiments}  % 4.1.1
            \dfn{A random \emph{experiment} is any activity in which there are at least two possible outcomes and the result of the activity can not be predicted with absolute certainty.}

            \nt{By this definition, all experiments are random.}

            \dfn{An \emph{outcome} is the result of an experiment.}

            \dfn{Each time the experiment is done is called a \emph{trial}.}
        \subsection{Tree Diagrams}  % 4.1.2
            \nt{This section is trivial}
        \subsection{Sample Spaces}  % 4.1.3
            \dfn{The \emph{sample space} of an experiment is the set of all possible outcomes, denoted by \emph{S} or $\Omega$.}
        \subsection{Events}  % 4.1.4
            \dfn{An \emph{event} is any collection of outcomes from an experiment. The sample space is one possible event.}

            \dfn{A \emph{simple event} only has one outcome.}

            We say that an event has occurred if the resulting outcome is containied in the event.
        \subsection{Set Theory}  % 4.1.5
            \dfn{The \emph{complement} of an event $A$ contains every outcome in the sample space that is not in $A$, denoted by $A'$.}
            
            \nt{Remainder of section is trivial.}

    \section{Introduction to Probability}  % 4.2
        \subsection{What is Probability?}  % 4.2.1
            \subsubsection{Frequentist POV}  % 4.2.1.1
                In the frequentist interpretation of probability, we say the probability of any outcome of any random experiment is the long term proportion of times that the outcome occurs over the total number of trials.
                \begin{equation}P(A)=\lim_{N\to\infty}\frac{n}{N}\end{equation}

            \subsubsection{Bayesian POV}  % 4.2.1.2
                In Bayesian probability, the probabilist specifices some \emph{prior probability}, which is then updated upon collection of \emph{relevant data}.

        \subsection{Properties}  % 4.2.2
            \begin{enumerate}
                \item Given any event $A$, it must be that $0\leq P(A) \leq 1$.
                \item Assuming $\omega$ is an outcome of $A$, then $P(A)=\sum P(\omega)$. That is, the sum of probabilities of all outcomes in an event is equal to the probability of the event.
                \item The probability of the sample space is 1. That is, $P(\Omega)=1$.
                \item The proability of the empty set is 0. That is, $P(\emptyset)=0$.
            \end{enumerate}

        \subsection{Rules}  % 4.2.3
            \textbf{Complement rule. } For any event $A$, $P(A')=1-P(A)$ \\
            \textbf{General additional rule. } $P(A\cup B)= P(A)+P(B)-P(A\cap B)$ \\
            \nt{When adding disjoint probabilities we need not subtract the last term, as the intersection will be empty.}

    \section{Conditional Probability and Independence}  % 4.3
        \subsection{What is conditional probability?}  % 4.3.1
            A \emph{conditional probability} is written $P(A\vert B)$ and is read `the probability of A, given that B occurs'.

        \subsection{General Multiplication Rule}  % 4.3.2
            To calculate a union (or `or'), we can use the general additional rule. To calculate an intersection (or `and'), we can use the general multiplication rule.
            \begin{equation}
                P(B\vert A)=\frac{P(B\cap A)}{P(A)} \implies P(A\cap B) = P(A)P(B\vert A) \\
            \end{equation}
            Additionally, this rule can be applied to an arbitrary number of unions.
            \begin{equation}
                P(A\cap B\cap C)=P(A)P(B\vert A)P(C\vert A\cap B)
            \end{equation}
        \subsection{Tree Diagrams revisited}  % 4.3.3
            \nt{Trivial}
        \subsection{Bayes' Rule using Tree Diagrams}  % 4.3.4
            \subsubsection{Bayes' rule}  % 4.3.4.1
                We use Bayes' rule when calculating a conditional probability in one direction, but you only know the conditional probability in the other direction. This method is not needed when the probability of the intersection is known. \\
                To find the probability of A given B,
                \begin{equation}
                    P(A\vert B)=\frac{P(A\cap B)}{P(B)}.
                \end{equation}
                If we don't know $P(A\cap B)$, we use the general multiplication rule to write
                \begin{equation}
                    P(A\vert B)=\frac{P(B\vert A)P(A)}{P(B)}.
                \end{equation}
                If we know what $P(B)$ is, we are done. Otherwise, we use the fact that
                \begin{equation}
                    P(B)=P(B\cap A)+P(B\cap A')=P(B\vert A)P(A) + P(B\vert A')P(A').
                \end{equation}
                This is called the \emph{Law of Total Probabilities for Two Variables}. \\
                Subbing eqn 4.6 into eqn 4.5, we get \emph{Bayes' Rule for two variables}:
                \begin{equation}
                    P(A\vert B)=\frac{P(B\vert A)P(A)}{P(B\vert A)P(A)+P(B\vert A')P(A')}
                \end{equation}
                For more than two variables, suppose the sample space is partitioned into $k$ disjoint events, $A_1, A_2, \ldots, A_k$, none of which have a probability of 0, such that
                \begin{equation} \sum^k_{i=1}P(A_i)=1 \end{equation}
                Then, the \emph{Law of Total Probability} is
                \begin{equation} \sum^k_{i=1}P(B\vert A_i)P(A_i) \end{equation}
                and Bayes' rule is
                \begin{equation} P(A_j\vert B)=\frac{P(B\vert A_j)P(A_j)}{\sum^k_{i=1}P(B\vert A_i)P(A_i)} \end{equation}
            \subsubsection{Bayesian Statistics}  % 4.3.3.1
                To summarize Bayesian Statistics, we first begin with a prior probability $A$. Then, given additional context, $B$, we can improve our prediction of the probability of $A$ by calculating $P(A\vert B)$. This is called the \emph{posterior} probability. In the example from the book, after someone tested positive for the disease, the probability that they have the disease increased from 0.01 to 0.165.
        \subsection{Independence}  % 4.3.5
            \dfn{Two events are \emph{independent} if knowing the outcome of one does not affect the outcome of the other. Mathematically, we write}
            \begin{equation} P(A\vert B)=P(A) \end{equation}
            \begin{equation} P(B\vert A)=P(B) \end{equation}
            or
            \begin{equation} P(A\cap B)=P(A)P(B\vert A)\implies P(A\cap B)=P(A)\times P(B) \end{equation}
            \subsubsection{Disjoint vs Independence}  % 4.3.5.1
                \dfn{Two events are \emph{disjoint} if they can not possibly occur at the same time.} \\
                \dfn{Two events are \emph{independent} if the outcome of one does not impact the other.}
                \begin{enumerate}
                    \item Draw a card. A: card is a heart, B: card is not a heart
                    \subitem disjoint; not independent
                    \item Toss 2 coins. A: first coin is head, B: second coin is head
                    \subitem not disjoint; independent
                    \item Roll 2 4-sided die. A: first die is 2, B: sum of die is 3
                    \subitem not disjoint; not independent
                \end{enumerate}
