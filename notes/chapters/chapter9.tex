\chapter{Confidence Intervals based on a Single Sample}  % 9

\section{Introduction to Statistical Inference}  % 9.1
interested in population mean, so we will use the statistic \(\bar{X}\)

\section{Point Estimation}  % 9.2
\subsection{Definitions}  % 9.2.1
\dfn{point estimate}{a single mumber computer from a sample; best guess for parameter (denoted by \(\theta\))}
\dfn{estimator}{statistic of interest; random variable}
\dfn{estimate}{value produced by estimator}
\nt{}{Do not need to estimate statistic since it has already been calculated, only need to estimate population parameter}

\subsection{Which estimator to use?}  % 9.2.2
look for certain properties in distribution\\
ideal distribution has \begin{enumerate}
    \item symmetry
    \item low variance
\end{enumerate}
\nt{warning}{low variance doesn't always mean estimator is accurate}

\subsection{Biased/Unbiased Estimators}  % 9.2.3
\dfn{unbiased estimator}{a statistic \(\hat{\theta}\) of a population parameter \(\theta\) if \(\EE(\hat{\theta})=\theta\)}
\dfn{biased estimator}{a statistic \(\hat{\theta}\) of a population parameter \(\theta\) if \(\EE(\hat{\theta})\neq\theta\)}
unbiased is usually better; can be rigorously shown that \(\bar X\) is an unbiased estimator for \(\mu\) of a normal distribution.
\ex{other unbiased estimators}{Sample proportion \(\hat{P}\) for estimating \(p\) because \(\EE(P)=p\)\\
Sample variance \(S\sq\) for estimating population variance \(\sigma\sq\) because \(\EE(S\sq)=\sigma\sq\)}
\begin{equation}
    \EE(S)=\EE(\sqrt{S\sq})=\sqrt{\EE(S\sq)}=\sqrt{\sigma\sq}=\sigma
\end{equation}

\subsection{Estimators with minimum variance}  % 9.2.4
\dfn{Minimum variance unbiased estimator (MVUE)}{the unbiased estimator of \(\theta\) with least variance}
\nt{}{the MVUE does not necessarily have to be symmetric}

\section{Confidence Interval (CI) for \(\mu\) (\(\sigma\) known)}  % 9.3
\subsection{Assumptions}  % 9.3.1
\nt{Necessary assumptions}{\begin{enumerate}
    \item data is sampled appropriately and generated by a random sample from a properly randomized experiment
    \item sampling distribution is normal (follows from CLT when \(n\) is large enough)
\end{enumerate}}

\subsection{Motivation}  % 9.3.2
smaller confidence interval gives more accurate idea of the true value of the parameter

\subsection{Derivation}  % 9.3.3
\begin{align}
    \mu_{\bar X} &= \mu_X \\
    \sigma_{\bar X} &= \frac{\sigma_X}{\sqrt n}
\end{align}

\nt{Naive solution}{We could use \(\bar x \pm \sigma_{\bar X}\) as interval, since 68\% of data is within 1 standard deviation. \\
Alternatively, use \(\bar x \pm 2\sigma_{\bar X}\) as interval, since 95\% of data is within 2 standard deviations.}

\subsection{Definitions}  % 9.3.4
\nt{Invoking CLT}{remember that \(n > 30\) is only a rule of thumb and exact number will depend on each distribution; extremely skewed distributions may require higher value of \(n\). }

\nt{Confidence Interval Formula}{All CIs are given by the formula \(estimate\pm margin\ of\ error\)}
\dfn{Confidence interval (CI)}{An interval of values constructed so that with a specified degree of confidence, the value of the population parameter lies in the interval}
\dfn{Confidence coefficient (C)}{The probability that the confidence encloses the popoulation parameter in repeated samplings. note that \(0\leq C \leq 1\).}
\dfn{Confidence level}{\(C\) expressed as a percentage. confidence level = 100C\%}

\subsection{Interpretation}  % 9.3.5
\dfn{Critical value (\(z_{\alpha/2}\))}{a value on the measurement axis in a standard normal distribution such that \begin{equation}
    P(Z\geq z_{\alpha/2})=\alpha/2
\end{equation}}
Thus \(z_{\alpha/2}\) is the z-value such that the area is \(\alpha/2\) to the right of the curve
\nt{useful relationshiops}{From the symmetry of the normal distribution, it follows that \begin{align}
    P(Z\leq -z_{\alpha/2}&)=\alpha/2 \\
    P(Z\leq z_{\alpha/2}&)=1-\alpha/2
\end{align}}
\nt{R code for \(z_{\alpha/2}\)}{z \(<-\) qnorm(alpha/2, lower.tail=FALSE)}

\subsection{Interpretation of CI}  % 9.3.6
\nt{Randomness of \(\mu\)}{\(\mu\) is NOT a random value; it represents a fixed parameter that we are solving for.}
\ex{Confidence}{CORRECT: ``We are 95\% confident that the interval contains \(\mu\)'' (implies \(\mu\) is random) \\
INCORRECT: ``We are 95\% confident that \(\mu\) lies in the interval'' (implies interval is random)}

\subsection{Precision of CI}  % 9.3.7
Recall the formula for margin of error
\begin{equation}
    ME=z_{\alpha/2}\frac{\sigma_X}{\sqrt n}
\end{equation}
Some possible methods for minimizing the margin of error are
\begin{enumerate}
    \item reduce critical value
    \item[] recall that higher confidence means wider interval, increasing confidence implies lowering precision. Thus, 100\% confidence implies the interval includes all possible outcomes, giving us no additional information.
    \item reduce \(\sigma\)
    \item[] lower variance means the data is more centralized, so a smaller interval will be able to capture a greater percentage of values.
    \item increase \(n\)
    \item[] recall that \(n\) is in the denominator of the equation for standard error, so a greater number of trials will decrease the standard deviation of the sampling distribution
\end{enumerate}

\subsubsection{Determining sample size}  % 9.3.7.1
Standard deviation is already as minimized as possible and confidence level depends on the specific experiment, so the only viable way to reduce the interval is increasing sample size. The sample size has to be an integer, so some algebraic manipulation of equation 9.7 gives
\begin{equation}
    n=\lt\lceil\lt(\frac{z_{\alpha/2}\cdot \sigma_X}{ME}\rt)\sq\rt\rceil
\end{equation}

\subsection{Practical procedure}  % 9.3.8
\begin{enumerate}
    \item plan experiment to minimize standard deviation as much as possible
    \item determine lowest acceptable confidence level
    \item determine largest acceptable width of confidence interval
    \item compute \(n\) with equation 9.8
    \item perform experiment
\end{enumerate}

\subsection{Confidence bounds}  % 9.3.9
\dfn{Confidence bound}{a one sided confidence interval; useful when only one direction matters}
\begin{align}
    \text{upper confidence bound:} \qquad &\mu < \bar x + z_{\alpha}\frac{\sigma}{\sqrt n} \\
    \text{lower confidence bound:} \qquad &\mu > \bar x - z_{\alpha}\frac{\sigma}{\sqrt n}
\end{align}

\section{Confidence Interval (CI) for \(\mu\) (\(\sigma\) unknown)}  % 9.4
\subsection{Assumptions}  % 9.4.1
don't know \(\mu\) or \(\sigma\), so use sample standard deviation \(s\) to estimate the population standard deviation \(\sigma\)

\subsection{Changes from when the standard deviation is known}  % 9.4.2
normalize critical value
\begin{equation}
    z=\frac{\bar x - \mu}{\sigma/n} \implies t=\frac{\bar x - \mu}{s/n}
\end{equation}
no longer standard normal; called t-distribution

\subsection{t-distribution}  % 9.4.3
t-distribution has more than one curve because the shape depends on ``degrees of freedom'', denoted by \(\nu\).
\begin{equation}
    \nu=n-1
\end{equation}
Note that as \(n\to\infty\), \(s\to\sigma\) and \(\mu_X\to \mu_{\bar X}\). Thus as \(n\to\infty\), the curve becomes the standard normal distribution

\subsection{Summary confidence interval/bounds for t distributions}  % 9.4.4
Confidence interval
\begin{equation}
    \bar x \pm t_{\alpha/2,n-1}\frac{s}{\sqrt n}
\end{equation}
upper confidence bound
\begin{equation}
    \mu < \bar x \pm t_{\alpha,n-1}\frac{s}{\sqrt n}
\end{equation}
lower confidence bound
\begin{equation}
    \mu > \bar x \pm t_{\alpha,n-1}\frac{s}{\sqrt n}
\end{equation}
sample size
\begin{equation}
    n=\left(\frac{t_{\alpha/2,n'-1}'s}{ME}\right)\sq
\end{equation}